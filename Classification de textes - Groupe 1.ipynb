{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtRw2scHOCAy",
        "outputId": "e77724e3-cf84-420d-af80-847dfc435ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informations sur le dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23514 entries, 0 to 23513\n",
            "Data columns (total 3 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Libellé.Prescription  23514 non-null  object \n",
            " 1   Avis.Pharmaceutique   23141 non-null  object \n",
            " 2   PLT                   23514 non-null  float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 551.2+ KB\n",
            "None\n",
            "\n",
            "Statistiques descriptives:\n",
            "                PLT\n",
            "count  23514.000000\n",
            "mean       3.903972\n",
            "std        3.397882\n",
            "min        1.100000\n",
            "25%        1.100000\n",
            "50%        2.200000\n",
            "75%        6.400000\n",
            "max       11.000000\n",
            "\n",
            "Valeurs manquantes:\n",
            "Libellé.Prescription      0\n",
            "Avis.Pharmaceutique     373\n",
            "PLT                       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Charger les données\n",
        "df = pd.read_csv('data_defi3.csv', sep=';')\n",
        "\n",
        "# Examiner les données\n",
        "print(\"Informations sur le dataset:\")\n",
        "print(df.info())\n",
        "print(\"\\nStatistiques descriptives:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(\"\\nValeurs manquantes:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnR_yD2JIj7z",
        "outputId": "368547c1-1cce-417b-dcc3-d94bbbb5d12b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribution des classes PLT:\n",
            "PLT\n",
            "1.1     10082\n",
            "1.2      1240\n",
            "1.3       139\n",
            "2.1        78\n",
            "2.2       280\n",
            "2.4       401\n",
            "3.1       952\n",
            "3.2        25\n",
            "4.1      2402\n",
            "4.2       670\n",
            "5.1       516\n",
            "5.2        31\n",
            "5.3       287\n",
            "6.1         4\n",
            "6.2       341\n",
            "6.3        89\n",
            "6.4       546\n",
            "7.0         8\n",
            "8.1        57\n",
            "8.2       387\n",
            "8.3      1059\n",
            "8.4       374\n",
            "8.5      1101\n",
            "9.1        20\n",
            "10.0      742\n",
            "11.0     1683\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution de la variable cible:\n",
            "est_grave\n",
            "0    18973\n",
            "1     4541\n",
            "Name: count, dtype: int64\n",
            "Proportion d'erreurs graves: 19.31%\n"
          ]
        }
      ],
      "source": [
        "# Examiner la distribution des classes PLT\n",
        "print(\"\\nDistribution des classes PLT:\")\n",
        "print(df['PLT'].value_counts().sort_index())\n",
        "\n",
        "# Créer la variable cible binaire\n",
        "# Classes graves: 4, 5, 6.3, 6.4\n",
        "classes_graves = [4.0, 4.1, 4.2, 4.3, 5.0, 5.1, 5.2, 5.3, 6.3, 6.4]\n",
        "df['est_grave'] = df['PLT'].apply(lambda x: 1 if x in classes_graves else 0)\n",
        "\n",
        "print(\"\\nDistribution de la variable cible:\")\n",
        "print(df['est_grave'].value_counts())\n",
        "print(f\"Proportion d'erreurs graves: {df['est_grave'].mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8CDBr33I-Tz",
        "outputId": "72f4301c-d40d-46a7-d7d7-ed6e089e0068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nombre de lignes après nettoyage: 23141\n"
          ]
        }
      ],
      "source": [
        "# Traiter les valeurs manquantes dans 'Avis.Pharmaceutique'\n",
        "# Option 1: Supprimer les lignes avec commentaires manquants\n",
        "df_clean = df.dropna(subset=['Avis.Pharmaceutique'])\n",
        "\n",
        "# Option 2 (alternative): Remplacer par une chaîne vide\n",
        "# df['Avis.Pharmaceutique'] = df['Avis.Pharmaceutique'].fillna('')\n",
        "\n",
        "print(f\"\\nNombre de lignes après nettoyage: {len(df_clean)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ1WQcsHJU2R",
        "outputId": "bf8a9850-2261-4934-da7a-a3fcc49353ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemples de textes nettoyés:\n",
            "\n",
            "Original: 30/12/16 pas d'indication \n",
            "Nettoyé:  pas indication\n",
            "\n",
            "Original: 22/12/16 recommandé -> IMOVANE 3,75MG CP, 1 au coucher. EB \n",
            "Nettoyé:  recommandé imovane 3 75mg cp 1 au coucher eb\n",
            "\n",
            "Original: au vue de la DFG, il est recommandé d'administrer 1mg/48h, (données GPR), Veuillez réévaluer la prescription, AB \n",
            "Nettoyé:  au vue de la dfg il est recommandé administrer 1mg 48h données gpr veuillez réévaluer la prescription ab\n",
            "\n",
            "Original: Dose curative et absence d'ATCD gastrique retrouvé, il es recommandé de réduire la posologie à 20 mg/jour   \n",
            "Nettoyé:  dose curative et absence atcd gastrique retrouvé il es recommandé de réduire la posologie à 20 mg jour\n",
            "\n",
            "Original: posologie infraT veuillez réévaluer la posologie, nous proposons 30mg/kG, AB \n",
            "Nettoyé:  posologie infrat veuillez réévaluer la posologie nous proposons 30mg kg ab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1604046701.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean['texte_nettoye'] = df_clean['Avis.Pharmaceutique'].apply(nettoyer_texte)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "def nettoyer_texte(texte):\n",
        "    \"\"\"\n",
        "    Nettoie le texte pharmaceutique\n",
        "    \"\"\"\n",
        "    if pd.isna(texte):\n",
        "        return \"\"\n",
        "\n",
        "    # Convertir en minuscules\n",
        "    texte = texte.lower()\n",
        "\n",
        "    # Supprimer les dates (format jj/mm/aa)\n",
        "    texte = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '', texte)\n",
        "\n",
        "    # Supprimer les ponctuations (virgules, points, etc.)\n",
        "    texte = re.sub(r'[,.\\:;\\!\\?\\-\\(\\)\\[\\]\\{\\}\\\"\\'\\/]', ' ', texte)\n",
        "\n",
        "    # Supprimer les chiffres seuls (garder les dosages comme \"3,75mg\")\n",
        "    # texte = re.sub(r'\\b\\d+\\b', '', texte)\n",
        "\n",
        "    # Supprimer les caractères spéciaux sauf les lettres, chiffres et espaces\n",
        "    texte = re.sub(r'[^\\w\\s,.]', ' ', texte)\n",
        "\n",
        "    # Supprimer les lettres seules (isolées)\n",
        "    texte = re.sub(r'\\b[a-z]\\b', '', texte)\n",
        "\n",
        "    # Supprimer les espaces multiples\n",
        "    texte = re.sub(r'\\s+', ' ', texte).strip()\n",
        "\n",
        "    return texte\n",
        "\n",
        "# Appliquer le nettoyage\n",
        "df_clean['texte_nettoye'] = df_clean['Avis.Pharmaceutique'].apply(nettoyer_texte)\n",
        "\n",
        "# Afficher quelques exemples\n",
        "print(\"\\nExemples de textes nettoyés:\")\n",
        "for i in range(5):\n",
        "    print(f\"\\nOriginal: {df_clean['Avis.Pharmaceutique'].iloc[i]}\")\n",
        "    print(f\"Nettoyé:  {df_clean['texte_nettoye'].iloc[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM0mm_WPLaBu",
        "outputId": "88929dd1-c562-4d55-a55e-5822b983fc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Longueur moyenne des commentaires: 72.9 caractères\n",
            "Nombre moyen de mots: 12.8 mots\n",
            "\n",
            "Statistiques par gravité:\n",
            "           longueur_texte    nb_mots\n",
            "est_grave                           \n",
            "0               71.690593  12.686080\n",
            "1               77.845406  13.363074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3480693702.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean['longueur_texte'] = df_clean['texte_nettoye'].apply(len)\n",
            "/tmp/ipython-input-3480693702.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_clean['nb_mots'] = df_clean['texte_nettoye'].apply(lambda x: len(x.split()))\n"
          ]
        }
      ],
      "source": [
        "# Longueur moyenne des commentaires\n",
        "df_clean['longueur_texte'] = df_clean['texte_nettoye'].apply(len)\n",
        "print(f\"\\nLongueur moyenne des commentaires: {df_clean['longueur_texte'].mean():.1f} caractères\")\n",
        "\n",
        "# Nombre moyen de mots\n",
        "df_clean['nb_mots'] = df_clean['texte_nettoye'].apply(lambda x: len(x.split()))\n",
        "print(f\"Nombre moyen de mots: {df_clean['nb_mots'].mean():.1f} mots\")\n",
        "\n",
        "# Comparer pour les cas graves vs non-graves\n",
        "print(\"\\nStatistiques par gravité:\")\n",
        "print(df_clean.groupby('est_grave')[['longueur_texte', 'nb_mots']].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5S1bPDbLstI",
        "outputId": "c2a3e8d9-4ed8-4bcc-bca1-974492f23540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Taille du jeu d'entraînement: 18512\n",
            "Taille du jeu de test: 4629\n",
            "\n",
            "Distribution dans le train: est_grave\n",
            "0    0.804343\n",
            "1    0.195657\n",
            "Name: proportion, dtype: float64\n",
            "Distribution dans le test: est_grave\n",
            "0    0.804277\n",
            "1    0.195723\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Séparer les features (X) et la cible (y)\n",
        "X = df_clean['texte_nettoye']\n",
        "y = df_clean['est_grave']\n",
        "\n",
        "# Division train/test (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # Préserver la proportion des classes\n",
        ")\n",
        "\n",
        "print(f\"\\nTaille du jeu d'entraînement: {len(X_train)}\")\n",
        "print(f\"Taille du jeu de test: {len(X_test)}\")\n",
        "print(f\"\\nDistribution dans le train: {y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Distribution dans le test: {y_test.value_counts(normalize=True)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf7XTr8qL8eH",
        "outputId": "6f838623-bc2d-4bf1-853d-d01d3c27a162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensions de la matrice TF-IDF train: (18512, 5000)\n",
            "Dimensions de la matrice TF-IDF test: (4629, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Créer le vectoriseur TF-IDF\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,      # Garder les 5000 mots les plus importants\n",
        "    ngram_range=(1, 2),     # Unigrammes et bigrammes\n",
        "    min_df=5,               # Ignorer les mots apparaissant dans < 5 documents\n",
        "    max_df=0.8,             # Ignorer les mots trop fréquents (> 80%)\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "\n",
        "# Transformer les données\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"\\nDimensions de la matrice TF-IDF train: {X_train_tfidf.shape}\")\n",
        "print(f\"Dimensions de la matrice TF-IDF test: {X_test_tfidf.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2YbCvIjMBRZ",
        "outputId": "97aef708-c5cd-4e10-800f-32c8b9e42ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RÉGRESSION LOGISTIQUE - RÉSULTATS\n",
            "============================================================\n",
            "\n",
            "Rapport de classification:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Grave       0.97      0.90      0.94      3723\n",
            "       Grave       0.69      0.89      0.78       906\n",
            "\n",
            "    accuracy                           0.90      4629\n",
            "   macro avg       0.83      0.90      0.86      4629\n",
            "weighted avg       0.92      0.90      0.90      4629\n",
            "\n",
            "\n",
            "Matrice de confusion:\n",
            "[[3360  363]\n",
            " [ 100  806]]\n",
            "\n",
            "ROC-AUC Score: 0.9662\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Créer et entraîner le modèle\n",
        "lr_model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',  # Important pour les classes déséquilibrées\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prédictions\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# Évaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RÉGRESSION LOGISTIQUE - RÉSULTATS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=['Non-Grave', 'Grave']))\n",
        "\n",
        "print(\"\\nMatrice de confusion:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu_qdKkgMTJI",
        "outputId": "538bad30-4847-4365-a6e6-4803fe90c8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "XGBOOST - RÉSULTATS\n",
            "============================================================\n",
            "\n",
            "Rapport de classification:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Grave       0.97      0.92      0.94      3723\n",
            "       Grave       0.72      0.87      0.79       906\n",
            "\n",
            "    accuracy                           0.91      4629\n",
            "   macro avg       0.85      0.89      0.87      4629\n",
            "weighted avg       0.92      0.91      0.91      4629\n",
            "\n",
            "\n",
            "ROC-AUC Score: 0.9576\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Calculer le ratio de déséquilibre\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "# Créer et entraîner le modèle\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,  # Gérer le déséquilibre\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prédictions\n",
        "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
        "y_pred_proba_xgb = xgb_model.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# Évaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"XGBOOST - RÉSULTATS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=['Non-Grave', 'Grave']))\n",
        "\n",
        "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm4tNlszMuMm",
        "outputId": "34fb448e-4f64-4721-81e5-e60b1b78fbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "RANDOM FOREST - RÉSULTATS\n",
            "============================================================\n",
            "\n",
            "Rapport de classification:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Grave       0.95      0.89      0.92      3723\n",
            "       Grave       0.65      0.81      0.72       906\n",
            "\n",
            "    accuracy                           0.88      4629\n",
            "   macro avg       0.80      0.85      0.82      4629\n",
            "weighted avg       0.89      0.88      0.88      4629\n",
            "\n",
            "\n",
            "ROC-AUC Score: 0.9286\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Créer et entraîner le modèle\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Utiliser tous les CPU\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prédictions\n",
        "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
        "y_pred_proba_rf = rf_model.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# Évaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RANDOM FOREST - RÉSULTATS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['Non-Grave', 'Grave']))\n",
        "\n",
        "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvfSdprM_fE",
        "outputId": "46b97055-6771-4206-a625-4f09ecb60c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "\n",
            "Meilleurs paramètres: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Meilleur score (ROC-AUC): 0.9561\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "# Exemple avec la Régression Logistique\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Force de régularisation\n",
        "    'penalty': ['l1', 'l2'],  # Type de régularisation\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Cross-validation stratifiée\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "    param_grid,\n",
        "    cv=cv,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"\\nMeilleurs paramètres:\", grid_search.best_params_)\n",
        "print(f\"Meilleur score (ROC-AUC): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Utiliser le meilleur modèle\n",
        "best_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Validation croisée avec 5 folds\n",
        "cv_scores = cross_val_score(\n",
        "    best_model,\n",
        "    X_train_tfidf,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "print(f\"\\nScores de validation croisée (ROC-AUC):\")\n",
        "print(f\"Scores: {cv_scores}\")\n",
        "print(f\"Moyenne: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NtZjjWsA0VS",
        "outputId": "12295beb-191d-45b0-d4a3-a105c3aed5f4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scores de validation croisée (ROC-AUC):\n",
            "Scores: [0.95597879 0.96089877 0.95470815 0.95556735 0.95485077]\n",
            "Moyenne: 0.9564 (+/- 0.0046)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour la régression logistique\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefficients = best_model.coef_[0]\n",
        "\n",
        "# Top 20 mots associés aux erreurs GRAVES\n",
        "top_grave = np.argsort(coefficients)[-20:]\n",
        "print(\"\\nTop 20 mots associés aux erreurs GRAVES:\")\n",
        "for idx in reversed(top_grave):\n",
        "    print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "# Top 20 mots associés aux erreurs NON-GRAVES\n",
        "top_non_grave = np.argsort(coefficients)[:20]\n",
        "print(\"\\nTop 20 mots associés aux erreurs NON-GRAVES:\")\n",
        "for idx in top_non_grave:\n",
        "    print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQLRB7gSIq2I",
        "outputId": "3e14abe0-f94c-4768-fe07-ed0f76e14c3c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 mots associés aux erreurs GRAVES:\n",
            "  max: 9.9582\n",
            "  doublon: 5.7833\n",
            "  indication: 5.4399\n",
            "  deja: 5.1683\n",
            "  suspendre: 5.1462\n",
            "  diminuer: 5.0312\n",
            "  maximum: 4.6034\n",
            "  arret: 4.4824\n",
            "  redondance: 4.3330\n",
            "  double: 4.1895\n",
            "  maximale: 3.9469\n",
            "  supprimer: 3.9271\n",
            "  arreter: 3.7833\n",
            "  association: 3.6548\n",
            "  stop: 3.3527\n",
            "  risque: 3.2993\n",
            "  lignes: 3.1262\n",
            "  avec: 3.0996\n",
            "  stopper: 2.9593\n",
            "  surdosage: 2.9526\n",
            "\n",
            "Top 20 mots associés aux erreurs NON-GRAVES:\n",
            "  substituer: -3.4492\n",
            "  substituer par: -3.4380\n",
            "  hus: -3.2324\n",
            "  avons: -3.0274\n",
            "  substitue: -2.9639\n",
            "  substitue par: -2.9491\n",
            "  lp: -2.5820\n",
            "  aux: -2.4993\n",
            "  par: -2.4977\n",
            "  prescrire: -2.4370\n",
            "  aux hus: -2.3974\n",
            "  pendant: -2.3950\n",
            "  prevoir: -2.3340\n",
            "  surveiller: -2.2325\n",
            "  preciser: -2.1103\n",
            "  gelules: -2.1098\n",
            "  substitution: -2.0483\n",
            "  comprimes: -2.0277\n",
            "  vie: -1.9840\n",
            "  hospitalisation: -1.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un DataFrame avec les prédictions\n",
        "results_df = pd.DataFrame({\n",
        "    'texte': X_test,\n",
        "    'vrai_label': y_test,\n",
        "    'prediction': y_pred_lr,\n",
        "    'probabilite': y_pred_proba_lr\n",
        "})\n",
        "\n",
        "# Faux positifs (prédit grave mais ne l'est pas)\n",
        "faux_positifs = results_df[(results_df['vrai_label'] == 0) & (results_df['prediction'] == 1)]\n",
        "print(\"\\nExemples de FAUX POSITIFS:\")\n",
        "print(faux_positifs.head(10))\n",
        "\n",
        "# Faux négatifs (prédit non-grave mais l'est)\n",
        "faux_negatifs = results_df[(results_df['vrai_label'] == 1) & (results_df['prediction'] == 0)]\n",
        "print(\"\\nExemples de FAUX NÉGATIFS:\")\n",
        "print(faux_negatifs.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apUzILs9I0PC",
        "outputId": "a8dee235-0965-4b3a-be42-b146c8e6ab03"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemples de FAUX POSITIFS:\n",
            "                                                   texte  vrai_label  \\\n",
            "10903  posologie à revoir prescrit 40ml soit 400mg de...           0   \n",
            "11763                     arrondir à 350mg 3 jour cécile           0   \n",
            "6170        refusé pour le motif suivant ne pas préparer           0   \n",
            "10319  dose curative 100 ui anti xa kg 2 soit pour un...           0   \n",
            "12526                         attention date de début eb           0   \n",
            "17787  la prudence est recommandée chez les patients ...           0   \n",
            "18391  non compatible avec cancidas et nutrition pare...           0   \n",
            "1989        habituellement 15mg kg jour soit 260 mg jour           0   \n",
            "620    au vu de âge et de la fragilité du patient ben...           0   \n",
            "22093  patient avec fonction rénale normale proposons...           0   \n",
            "\n",
            "       prediction  probabilite  \n",
            "10903           1     0.702136  \n",
            "11763           1     0.636549  \n",
            "6170            1     0.803856  \n",
            "10319           1     0.512808  \n",
            "12526           1     0.701263  \n",
            "17787           1     0.557853  \n",
            "18391           1     0.579896  \n",
            "1989            1     0.648698  \n",
            "620             1     0.540815  \n",
            "22093           1     0.504971  \n",
            "\n",
            "Exemples de FAUX NÉGATIFS:\n",
            "                                                   texte  vrai_label  \\\n",
            "18524  dosage doit être réduit car clcr 60mg ml poso ...           1   \n",
            "23071  refusé pour le motif suivant revoir prescripti...           1   \n",
            "1249                                     hyperk le 23 06           1   \n",
            "6064                   instauré en post op arrêter agnès           1   \n",
            "12232   50mg 1 2 comprimé à 100mg diphantoine ou dihydan           1   \n",
            "22603  le patient prend habituellement 1 2 cp revoir ...           1   \n",
            "18197  glucidion contient 2 kcl kaliémie 5 16 mm envi...           1   \n",
            "2440   cp non sécable proposons telmisartan 40 mg cp ...           1   \n",
            "14753  posologie max dépassée une seule dose gél pour...           1   \n",
            "15507  actif sur staphylococcus hominis hémoculture 1...           1   \n",
            "\n",
            "       prediction  probabilite  \n",
            "18524           0     0.201398  \n",
            "23071           0     0.440825  \n",
            "1249            0     0.483926  \n",
            "6064            0     0.489291  \n",
            "12232           0     0.351331  \n",
            "22603           0     0.403542  \n",
            "18197           0     0.295637  \n",
            "2440            0     0.116248  \n",
            "14753           0     0.222543  \n",
            "15507           0     0.360663  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "# Courbe précision-recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_lr)\n",
        "\n",
        "# Trouver le seuil optimal pour maximiser le F1-score\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"\\nSeuil optimal: {optimal_threshold:.3f}\")\n",
        "print(f\"F1-score au seuil optimal: {f1_scores[optimal_idx]:.4f}\")\n",
        "print(f\"Précision: {precision[optimal_idx]:.4f}\")\n",
        "print(f\"Rappel: {recall[optimal_idx]:.4f}\")\n",
        "\n",
        "# Appliquer le seuil optimal\n",
        "y_pred_optimal = (y_pred_proba_lr >= optimal_threshold).astype(int)\n",
        "\n",
        "print(\"\\nPerformances avec le seuil optimal:\")\n",
        "print(classification_report(y_test, y_pred_optimal, target_names=['Non-Grave', 'Grave']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mb7eNjsI7Hq",
        "outputId": "7c2d8478-5cca-42af-f79c-b82d1e61db5f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seuil optimal: 0.681\n",
            "F1-score au seuil optimal: 0.8210\n",
            "Précision: 0.8491\n",
            "Rappel: 0.7947\n",
            "\n",
            "Performances avec le seuil optimal:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Grave       0.95      0.97      0.96      3723\n",
            "       Grave       0.85      0.79      0.82       906\n",
            "\n",
            "    accuracy                           0.93      4629\n",
            "   macro avg       0.90      0.88      0.89      4629\n",
            "weighted avg       0.93      0.93      0.93      4629\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Sauvegarder le modèle et le vectoriseur\n",
        "joblib.dump(best_model, 'modele_classification_ip.pkl')\n",
        "joblib.dump(tfidf, 'vectoriseur_tfidf.pkl')\n",
        "\n",
        "print(\"\\nModèle et vectoriseur sauvegardés!\")\n",
        "\n",
        "# Pour réutiliser plus tard:\n",
        "# modele_charge = joblib.load('modele_classification_ip.pkl')\n",
        "# tfidf_charge = joblib.load('vectoriseur_tfidf.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ves54hxwI_ip",
        "outputId": "2ef1d5cc-fa54-4480-eeb9-3f698bdf3223"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modèle et vectoriseur sauvegardés!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}